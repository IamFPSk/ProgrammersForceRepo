{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "0YbtMCp7CBR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WnmJaxGCAjn",
        "outputId": "879ce684-3ed0-4191-98c1-6e16b12cb2b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading CSV**"
      ],
      "metadata": {
        "id": "4Thtqn5VD1e0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHVctx9aBuK2",
        "outputId": "28f8eac8-5c68-423e-ccdd-6790d547e8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6   ham  Even my brother is not like to speak with me. ...\n",
            "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8  spam  WINNER!! As a valued network customer you have...\n",
            "9  spam  Had your mobile 11 months or more? U R entitle...\n"
          ]
        }
      ],
      "source": [
        "text = pd.read_csv('/content/spam.csv', sep=',', encoding='latin-1')\n",
        "text.drop(columns=text.columns[text.columns.str.contains('unnamed', case=False)], inplace=True)\n",
        "print(text.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "GuNIMPoXDy5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "  # Removing HTML tags\n",
        "  text_cleaned = re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "  # Removing URLs\n",
        "  text_cleaned = re.sub(r'http\\S+|www\\S+|https\\S+', '', text_cleaned)\n",
        "\n",
        "  # Converting to lowercase and removing non-alphanumeric characters\n",
        "  text_cleaned = re.sub(r'[^a-zA-Z\\s]', '', text_cleaned.lower())\n",
        "\n",
        "  # Tokenization\n",
        "  tokens = word_tokenize(text_cleaned)\n",
        "\n",
        "  # Removing stopwords\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens_without_sw = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  # Regex: Remove punctuation marks\n",
        "  tokens_without_punctuation = [word for word in tokens_without_sw if re.match(r'^\\w+$', word)]\n",
        "\n",
        "  # Lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens_without_punctuation]\n",
        "\n",
        "  return \" \".join(lemmatized_tokens)\n",
        "\n",
        "text['processed_text'] = text['v2'].apply(preprocessing)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2aHcpqAD0xt",
        "outputId": "1cb76d2b-99e8-4e78-ef73-ad8812168c50"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        v1                                                 v2  \\\n",
            "0      ham  Go until jurong point, crazy.. Available only ...   \n",
            "1      ham                      Ok lar... Joking wif u oni...   \n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3      ham  U dun say so early hor... U c already then say...   \n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
            "...    ...                                                ...   \n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
            "5568   ham              Will ÃŒ_ b going to esplanade fr home?   \n",
            "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
            "5570   ham  The guy did some bitching but I acted like i'd...   \n",
            "5571   ham                         Rofl. Its true to its name   \n",
            "\n",
            "                                         processed_text  \n",
            "0     go jurong point crazy available bugis n great ...  \n",
            "1                               ok lar joking wif u oni  \n",
            "2     free entry wkly comp win fa cup final tkts st ...  \n",
            "3                   u dun say early hor u c already say  \n",
            "4              nah dont think go usf life around though  \n",
            "...                                                 ...  \n",
            "5567  nd time tried contact u u pound prize claim ea...  \n",
            "5568                          b going esplanade fr home  \n",
            "5569                         pity mood soany suggestion  \n",
            "5570  guy bitching acted like id interested buying s...  \n",
            "5571                                     rofl true name  \n",
            "\n",
            "[5572 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "6TNRZe8NJ69V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(text['processed_text'])\n",
        "print(bow_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99MyvxTQKiZA",
        "outputId": "a470898b-375f-4d68-c6b5-057d5c04c030"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 2640)\t1\n",
            "  (0, 3456)\t1\n",
            "  (0, 5057)\t1\n",
            "  (0, 1445)\t1\n",
            "  (0, 458)\t1\n",
            "  (0, 879)\t1\n",
            "  (0, 2728)\t1\n",
            "  (0, 7590)\t1\n",
            "  (0, 3600)\t1\n",
            "  (0, 877)\t1\n",
            "  (0, 1182)\t1\n",
            "  (0, 2692)\t1\n",
            "  (0, 231)\t1\n",
            "  (0, 7369)\t1\n",
            "  (1, 4643)\t1\n",
            "  (1, 3633)\t1\n",
            "  (1, 3426)\t1\n",
            "  (1, 7492)\t1\n",
            "  (1, 4674)\t1\n",
            "  (2, 2445)\t1\n",
            "  (2, 2059)\t2\n",
            "  (2, 7546)\t1\n",
            "  (2, 1290)\t1\n",
            "  (2, 7505)\t1\n",
            "  (2, 2188)\t2\n",
            "  :\t:\n",
            "  (5567, 866)\t1\n",
            "  (5568, 3006)\t1\n",
            "  (5568, 2655)\t1\n",
            "  (5568, 2432)\t1\n",
            "  (5568, 2086)\t1\n",
            "  (5569, 4245)\t1\n",
            "  (5569, 6485)\t1\n",
            "  (5569, 4982)\t1\n",
            "  (5569, 6140)\t1\n",
            "  (5570, 2445)\t1\n",
            "  (5570, 7415)\t1\n",
            "  (5570, 3135)\t1\n",
            "  (5570, 3737)\t1\n",
            "  (5570, 4445)\t1\n",
            "  (5570, 6163)\t1\n",
            "  (5570, 2005)\t1\n",
            "  (5570, 2555)\t1\n",
            "  (5570, 910)\t1\n",
            "  (5570, 2788)\t1\n",
            "  (5570, 3265)\t1\n",
            "  (5570, 60)\t1\n",
            "  (5570, 686)\t1\n",
            "  (5571, 4363)\t1\n",
            "  (5571, 6994)\t1\n",
            "  (5571, 5635)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the BoW matrix to a DataFrame\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "print(bow_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9xvd9nPLRoU",
        "outputId": "4aee6e45-f9de-4384-cab3-3ed5a0a0e1ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      aa  aah  aaniye  aaooooright  aathilove  aathiwhere  ab  abbey  abdomen  \\\n",
            "0      0    0       0            0          0           0   0      0        0   \n",
            "1      0    0       0            0          0           0   0      0        0   \n",
            "2      0    0       0            0          0           0   0      0        0   \n",
            "3      0    0       0            0          0           0   0      0        0   \n",
            "4      0    0       0            0          0           0   0      0        0   \n",
            "...   ..  ...     ...          ...        ...         ...  ..    ...      ...   \n",
            "5567   0    0       0            0          0           0   0      0        0   \n",
            "5568   0    0       0            0          0           0   0      0        0   \n",
            "5569   0    0       0            0          0           0   0      0        0   \n",
            "5570   0    0       0            0          0           0   0      0        0   \n",
            "5571   0    0       0            0          0           0   0      0        0   \n",
            "\n",
            "      abeg  ...  zed  zero  zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  \\\n",
            "0        0  ...    0     0   0      0       0    0          0     0     0   \n",
            "1        0  ...    0     0   0      0       0    0          0     0     0   \n",
            "2        0  ...    0     0   0      0       0    0          0     0     0   \n",
            "3        0  ...    0     0   0      0       0    0          0     0     0   \n",
            "4        0  ...    0     0   0      0       0    0          0     0     0   \n",
            "...    ...  ...  ...   ...  ..    ...     ...  ...        ...   ...   ...   \n",
            "5567     0  ...    0     0   0      0       0    0          0     0     0   \n",
            "5568     0  ...    0     0   0      0       0    0          0     0     0   \n",
            "5569     0  ...    0     0   0      0       0    0          0     0     0   \n",
            "5570     0  ...    0     0   0      0       0    0          0     0     0   \n",
            "5571     0  ...    0     0   0      0       0    0          0     0     0   \n",
            "\n",
            "      zyada  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "...     ...  \n",
            "5567      0  \n",
            "5568      0  \n",
            "5569      0  \n",
            "5570      0  \n",
            "5571      0  \n",
            "\n",
            "[5572 rows x 7792 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF IDF**"
      ],
      "metadata": {
        "id": "OZhbA9zDLuno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(text['processed_text'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD0931bqLxli",
        "outputId": "60274570-e729-4804-d13f-9ea52bc12e67"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       aa  aah  aaniye  aaooooright  aathilove  aathiwhere   ab  abbey  \\\n",
            "0     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "1     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "2     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "3     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "4     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "...   ...  ...     ...          ...        ...         ...  ...    ...   \n",
            "5567  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "5568  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "5569  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "5570  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "5571  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
            "\n",
            "      abdomen  abeg  ...  zed  zero   zf  zhong  zindgi  zoe  zogtorius  zoom  \\\n",
            "0         0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "1         0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "2         0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "3         0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "4         0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "...       ...   ...  ...  ...   ...  ...    ...     ...  ...        ...   ...   \n",
            "5567      0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "5568      0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "5569      0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "5570      0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "5571      0.0   0.0  ...  0.0   0.0  0.0    0.0     0.0  0.0        0.0   0.0   \n",
            "\n",
            "      zouk  zyada  \n",
            "0      0.0    0.0  \n",
            "1      0.0    0.0  \n",
            "2      0.0    0.0  \n",
            "3      0.0    0.0  \n",
            "4      0.0    0.0  \n",
            "...    ...    ...  \n",
            "5567   0.0    0.0  \n",
            "5568   0.0    0.0  \n",
            "5569   0.0    0.0  \n",
            "5570   0.0    0.0  \n",
            "5571   0.0    0.0  \n",
            "\n",
            "[5572 rows x 7792 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression model on TF IDF and BoW**"
      ],
      "metadata": {
        "id": "o280wCSlM5VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(tfidf_matrix, text['v1'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yX2lgeYGM7SE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Model with TF IDF"
      ],
      "metadata": {
        "id": "dlmMdXHXPKHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression with TF-IDF\n",
        "logreg_tfidf = LogisticRegression()\n",
        "logreg_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_tfidf = logreg_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(\"Logistic Regression Accuracy with TF-IDF:\", accuracy_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pX58BdCPRdW",
        "outputId": "1ee1f565-f513-462f-cf3a-a4ae023fc896"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy with TF-IDF: 0.9488789237668162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Model with BOW"
      ],
      "metadata": {
        "id": "f-0ymJ14PWBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(bow_matrix, text['v1'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2DZUFNloPYHE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression with Bag of Words\n",
        "logreg_bow = LogisticRegression()\n",
        "logreg_bow.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bow = logreg_bow.predict(X_test_bow)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
        "print(\"Logistic Regression Accuracy with Bag of Words:\", accuracy_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLEU_0rPdlB",
        "outputId": "0e2720f9-9bd8-4194-eb3e-b8cabbafe690"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy with Bag of Words: 0.9775784753363229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM Model on TF-IDF and Bag of Words**"
      ],
      "metadata": {
        "id": "ZGBJ5N47PtQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(tfidf_matrix, text['v1'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Dy7E8el7QC2b"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model on TF-IDF"
      ],
      "metadata": {
        "id": "FVG5EVZxQxcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM with TF-IDF\n",
        "svm_tfidf = SVC(kernel='linear')\n",
        "svm_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(\"SVM Accuracy with TF-IDF:\", accuracy_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kFnMCeGQHXd",
        "outputId": "04918181-3d39-4190-efb4-7b09215891ac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy with TF-IDF: 0.9757847533632287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model on BOW"
      ],
      "metadata": {
        "id": "Vui1ys78QwPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(bow_matrix, text['v1'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1sS5DFLYQ6u_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM with Bag of Words\n",
        "svm_bow = SVC(kernel='linear')\n",
        "svm_bow.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bow = svm_bow.predict(X_test_bow)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
        "print(\"SVM Accuracy with Bag of Words:\", accuracy_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uRPzYwjQ1Sr",
        "outputId": "45ff470c-1edc-4c14-8edb-483ca8719e1d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy with Bag of Words: 0.9748878923766816\n"
          ]
        }
      ]
    }
  ]
}